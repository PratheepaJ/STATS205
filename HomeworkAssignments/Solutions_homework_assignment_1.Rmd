---
title: "STATS 205: Solutions for Homework Assignment 1 (Spring 2019)"
author: "Pratheepa Jeganathan"
date: "4/12/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

Solve these problems from the textbook [HWC](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119196037).

### Soultion for problem 1) (Sign test) HWC: page 74: (44) [4 points]

Change the value of $Y_{3}$ in Table 3.5 from 73 to 173. What effect does this outlying observation have on the calculations performed in Example 3.5? What does this suggest about the relative insensitivity of the sign tests to outliers? Construct an example in which changing one observation has an effect on the final decision regarding rejection or acceptance of $\text{H}_{0}$.
```{r}
df = data.frame(X = c(5.8,13.5,26.1,7.4,7.6,23,10.7,9.1,
  19.3,26.3,17.5,17.9,18.3,14.2,55.2,15.4,30,21.3,
  26.8,8.1,24.3, 21.3,18.2,22.5,31.1), 
  Y = c(5,21,73,25,3,77,59,13,36,46,9,25,
    59,38,70,36,55,46,25,30,29,46,71,31,33))
head(df)
```

Let's do the sign test
```{r}
library(BSDA)
SIGN.test(x = df$Y, y=df$X, alt= "greater")
```

Change $Y_{3}$ to 173.
```{r}
df[3, "Y"] = 173
head(df)
```

Let's do the sign test after changing the value
```{r}
library(BSDA)
SIGN.test(x = df$Y, y=df$X, alt= "greater")
```

Changing $Y_{3}$ in Table 3.5 from 73 to 173 does not change the value of observed statistic $B = 21$. 

Sign tests are relatively insensitive to outliers. The value of the test statistic will only change with a change of sign (not the size). 

**An example in which changing one observation has an effect on the final decision regarding rejection or acceptance of $\text{H}_{0}$**. 

Let's consider 10 observations of $Z$. Let's find out possible p-values under $\text{H}_{0}: \theta = 0$. 

$\text{H}_{0}: \theta = 0$ versus $\text{H}_{A}: \theta > 0$.

Sign test statistic $B \sim \text{Bin}\left(10, .5\right)$.

Compute $P\left(B \geq 1\right), P\left(B \geq 2\right), P\left(B \geq 3\right), \cdots P\left(B \geq 9\right), P\left(B \geq 10\right)$. This gives the possible p-values.

```{r}
1-pbinom(seq(0,9),size = 10, prob = .5)
```

These possible p-values tell us that if the observed test statistic value is 7, then $P\left(B \geq 8\right) = .055$ (we do not reject $\text{H}_{0}$ at 5\% significance level) and if it is increased to 8, $P\left(B \geq 8\right) = .011$ (we reject $\text{H}_{0}$ at 5\% significance level). 

We will generate 10 observations with 7 positive values. Then, we will change one negative value to positive value. This will be an example in which changing one observation has an effect on the final decision regarding rejection or acceptance of $\text{H}_{0}$.

```{r}
library(BSDA)
x = c(-20,-15,-10, 5, 15, 20, 25, 30, 35, 38, 26)
SIGN.test(x, alternative = "greater")
```

We do not have enough evidence to reject $\text{H}_{0}$ in favor of $\theta > 0$ at 5\% significance level.

Now change the third observation to a positive value
```{r}
x[3] = 10
SIGN.test(x, alternative = "greater")
```

We reject $\text{H}_{0}$ in favor of $\theta > 0$ at 5\% significance level.

### Soultion for problem 2) (Sign test) HWC: page 74: (45) [4 points]
Suppose $n=25$. Compare the exact P-value of test of $\text{H}_{0} :\theta = 0$ versus $\text{H}_{a} :\theta < 0$ based on $B = 8$, with the P -value found using the large-sample approximation.

The exact p-value based on the sign test is $P\left(B \leq 8\right)$.

```{r}
exact.pvalue = pbinom(8,size = 25, prob = .5);exact.pvalue
```

The large-sample p-value is $P\left(B^{*} \leq \dfrac{8-25(.5)}{\sqrt{25(.5)(.5)}}\right)$, where $B^{*} \sim \text{N}\left(0, 1\right)$.

```{r}
B.star = (8-25*(.5))/sqrt(25*(.5)*(.5)); B.star
appro.pvlaue = pnorm(B.star); appro.pvlaue
```


### Soultion for problem 3) (Wilcoxon signed rank test) HWC: page 54: (4) [4 points]

August, Hung, and Houck (1974) studied collagen metabolism in children deficient in growth hormone before and after growth hormone therapy. The data in Table 3.4 are the values of heat-insoluble hydroxyproline in the skin of children before and 3 months after growth hormone therapy. Can we conclude on the basis of these data that growth hormone therapy increases
heat-insoluble hydroxyproline in the skin?

Let $X=$ heat-insoluble hydroxyproline in the skin before growth hormone therapy,

$Y=$ heat-insoluble hydroxyproline in the skin after growth hormone therapy,

$Z= Y - X$ difference of heat-insoluble hydroxyproline in the skin after and before growth hormone therapy.

Let $\theta$ is the location parameter of $Z$. 

$\text{H}_{0}: \theta = 0$ versus $\text{H}_{0}: \theta > 0$

```{r}
x.before = c(349, 400, 520, 490, 574, 427, 435)
y.after = c(425, 533, 362, 628, 463, 427, 449)
z.difference = y.after - x.before
boxplot(z.difference)
```

$Z$ has a symmetric distribution. We will use Wilcoxon signed rank test.

```{r}
wilcox.test(x = z.difference, alternative = "greater", correct = TRUE)
```
Because p-value is greater than the significance level $\alpha = .05$, we do not have enough evidence to reject $\text{H}_{0}$ in favor of the growth hormone therapy increases heat-insoluble hydroxyproline in the skin.

### Soultion for problem 4) (Sign test point estimate) HWC: page 79: (61) [4 points]

Calculate $\tilde{\theta}$ for the heat-insoluble hydroxyproline data of Table 3.4. Compare with the value of $\hat{\theta}$ obtained in Problem 21.


$\tilde{\theta}$ median of difference. 
```{r}
median(z.difference)
```


$\hat{\theta}$ Hodges-Lehman estimator. 
```{r}
library(ICSNP)
hl.loc(z.difference)
```

Median $\tilde{\theta} = 14$ and Hodges-Lehman $\hat{\theta} = 12.25$.


### Soultion for problem 5) (Sign test interval estimate) HWC: page 84: (77) [4 points]

For the beak-clapping data of Table 3.5, find a lower confidence bound for $\theta$ with the exact confidence coefficient .9461. (See Comment 49.)
Let 
$X =$ average number of claps per minute during the dark
period.
$Y =$ average number of claps per minute during the period of
illumination.

```{r}
df = data.frame(X = c(5.8,13.5,26.1,7.4,7.6,23,10.7,9.1, 19.3,26.3,17.5,17.9,18.3,
  14.2,55.2,15.4,30,21.3, 26.8,8.1,24.3,
  21.3,18.2,22.5,31.1),
Y = c(5,21,73,25,3,77,59,13,36,46,9,25,
59,38,70,36,55,46,25,30,29,46,71,31,33)) ;head(df)
```

Compute $Z = Y-X$.
```{r}
library(dplyr)
df = mutate(df, Z= Y-X, Psi = ifelse(Z > 0 ,1,0)); head(df)
```


```{r}
SIGN.test(x= df$Z, alternative = "greater", conf.level = .9461)
```

The lower confidence bound for $\theta$ with the exact confidence coefficient .9461 is 7.5.

### Soultion for problem 6) (Wilcoxon signed rank test point estimate) HWC: page 58: (21) [4 points]

Estimate $\theta$ for the heat-insoluble hydroxyproline data of Table 3.4.
```{r}
Table.3.4 = data.frame(before = c(349, 400, 520, 490, 574, 427, 435),
  after = c(425, 533, 362, 628, 463, 427, 449)); Table.3.4
diff =  Table.3.4$after - Table.3.4$before
```

Hodges-Lehman estimate for $\theta$ is
```{r}
library(ICSNP) 
hl.loc(diff)
```

### Soultion for problem 7) (Wilcoxon signed rank test statistic and Walsh averages) HWC: page 58: (22) [4 points]

Verify directly, or illustrate using the data of Table 3.1, that (when there are no ties among the absolute values of the Z’s and none of the Z’s is zero) $T^{+}$ is equal to the number of positive Walsh averages $W^{+}$. (See Comment 17.)

We will use Table 3.1
```{r}
Table.3.1 = data.frame(X = c(1.83, 0.50, 1.62, 2.48, 1.68, 1.88, 1.55, 3.06, 1.30), 
  Y = c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)); Table.3.1
```

Let us define the difference $Z = Y -X$.
```{r}
Z = Table.3.1$Y - Table.3.1$X
Z
```

$T^{+} = \sum_{i=1}^{9}I\left(Z_{i} > 0\right)R_{i}$
```{r}
library(NSM3)  # if there is problem in installing NSM3, you need to update dplyr package.
wilcox.test(Table.3.1$Y, Table.3.1$X, paired=TRUE, alterative = "greater")
```

$T^{+} = 5$.

Compute Walsh averages of $Z$
```{r}
library(Rfit)
Ws = walsh(Z)
```

$W^{+} = \sum_{i=1}^{9}I\left(W_{i} > 0\right)$
```{r}
W.plus = sum(Ws > 0); W.plus
```

We have shown that Wilcoxon signed rank test statistic value $T^{+} = 5$ is equal to total of Walsh averages greater than zero $W^{+} = 5$.

### Soultion for problem 8) (Wilcoxon signed rank test point estimate) HWC: page 58: (23(a,b)) [4 points]

(i) What happens to $\hat{\theta}$ (Hodges-Lehman) when we add a number $b$ to each of the sample values $Z_{1}, \cdots, Z_{n}$?

Let us use the previous problem $Z$ values.
```{r}
Z
```

Compute $\hat{\theta}$ (Hodges-Lehman) of $Z_{1}, \cdots, Z_{n}$
```{r}
library(ICSNP) 
hl.loc(Z)
```

Let $b = 10$ and add it to each $Z_{i}$
```{r}
Z.add.10 = Z+10;Z.add.10
```

Compute $\hat{\theta}$ (Hodges-Lehman) of $Z.add.10$
```{r}
hl.loc(Z.add.10)
```

We observe that 
```{r}
hl.loc(Z)-hl.loc(Z.add.10)
```
 
Hodges-Lehman estimate is increased by the constant that we added to each $Z$.


(ii) What happens to $\hat{\theta}$ (Hodges-Lehman) when we multiply each sample value $Z_{1}, \cdots, Z_{n}$ by a number $d$?

Let us use the previous problem $Z$ values. Let $d = 5$ and multiply each $Z_{i}$ by $d$.

```{r}
Z.multiply.5 = Z*5; Z.multiply.5
```

Compute $\hat{\theta}$ (Hodges-Lehman) of $Z.multiply.5$
```{r}
hl.loc(Z.multiply.5)
```

We observe that 
```{r}
hl.loc(Z.multiply.5)/hl.loc(Z)
```

Hodges-Lehman estimate is multiplied by the constant that we used to multiply each $Z$.

### Soultion for problem 9) (Wilcoxon signed rank test interval estimate) HWC: page 62: (28) [4 points]

For the heat-insoluble hydroxyproline data of Table 3.4, obtain a confidence interval for $\theta$ with the exact confidence coefficient .922.

```{r}
wilcox.test(Table.3.4$after - Table.3.4$before, conf.int=T, conf.level= .922)
```

92.2\% confidence interval for $\theta$ is $\left(-134.5, 135.5\right)$.

